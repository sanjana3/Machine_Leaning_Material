{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading Files, Selecting Columns, and Summarizing\n",
    "‘’’\n",
    "# reading in a file from local computer or directly from a URL\n",
    "# various file formats that can be read in out wrote out\n",
    "‘’’\n",
    "Format Type     Data Description      Reader           Writer\n",
    "text                  CSV            read_csv          to_csv\n",
    "text                 JSON            read_json         to_json\n",
    "text                 HTML            read_html         to_html\n",
    "text             Local clipboard  read_clipboard     to_clipboard\n",
    "binary             MS Excel          read_excel        to_excel\n",
    "binary            HDF5 Format        read_hdf           to_hdf\n",
    "binary           Feather Format     read_feather      to_feather\n",
    "binary              Msgpack         read_msgpack      to_msgpack\n",
    "binary               Stata           read_stata        to_stata\n",
    "binary                SAS             read_sas \n",
    "'''\n",
    "#df = pd.read_csv(‘local_path\\file.csv’)\n",
    "#df = pd.read_csv(‘https://file_path/file.csv')\n",
    "\n",
    "df = pd.read_excel('D:\\Data_Analytics-Tableau\\cuisine_traindata.xls')\n",
    "df2 = pd.read_json(r'C:\\Users\\raja3\\Downloads\\cuisinetraindata.json',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['greek', 10259,\n",
       "        list(['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles'])],\n",
       "       ['southern_us', 25693,\n",
       "        list(['plain flour', 'ground pepper', 'salt', 'tomatoes', 'ground black pepper', 'thyme', 'eggs', 'green tomatoes', 'yellow corn meal', 'milk', 'vegetable oil'])],\n",
       "       ['filipino', 20130,\n",
       "        list(['eggs', 'pepper', 'salt', 'mayonaise', 'cooking oil', 'green chilies', 'grilled chicken breasts', 'garlic powder', 'yellow onion', 'soy sauce', 'butter', 'chicken livers'])],\n",
       "       ...,\n",
       "       ['irish', 2238,\n",
       "        list(['eggs', 'citrus fruit', 'raisins', 'sourdough starter', 'flour', 'hot tea', 'sugar', 'ground nutmeg', 'salt', 'ground cinnamon', 'milk', 'butter'])],\n",
       "       ['chinese', 41882,\n",
       "        list(['boneless chicken skinless thigh', 'minced garlic', 'steamed white rice', 'baking powder', 'corn starch', 'dark soy sauce', 'kosher salt', 'peanuts', 'flour', 'scallions', 'Chinese rice vinegar', 'vodka', 'fresh ginger', 'egg whites', 'broccoli', 'toasted sesame seeds', 'sugar', 'store bought low sodium chicken stock', 'baking soda', 'Shaoxing wine', 'oil'])],\n",
       "       ['mexican', 2362,\n",
       "        list(['green chile', 'jalapeno chilies', 'onions', 'ground black pepper', 'salt', 'chopped cilantro fresh', 'green bell pepper', 'garlic', 'white sugar', 'roma tomatoes', 'celery', 'dried oregano'])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To examine the dataframe data\n",
    "df1           # print the first 30 and last 30 rows\n",
    "type(df1)     # DataFrame\n",
    "df1.head()    # print the first 5 rows\n",
    "df1.head(10)  # print the first 10 rows\n",
    "df1.tail()    # print the last 5 rows\n",
    "df1.index     # “the index” (aka “the labels”)\n",
    "df1.columns   # column names (which is “an index”)\n",
    "df1.dtypes    # data types of each column\n",
    "df1.shape     # number of rows and columns\n",
    "df1.values    # underlying numpy array — df are stored as numpy arrays for effeciencies.\n",
    "\n",
    "# select a column\n",
    "df['column_y']         # select one column\n",
    "type(df['column_y'])   # determine datatype of column (e.g., Series)\n",
    "df.column_y            # select one column using the DataFrame attribute — not effective if column names have spaces\n",
    "\n",
    "# summarize (describe) the DataFrame\n",
    "df.describe()          # describe all numeric columns\n",
    "df.describe(include=['object']) # describe all object columns\n",
    "df.describe(include='all')      # describe all columns\n",
    "\n",
    "# summarize a Series\n",
    "df.column_y.describe()   # describe a single column\n",
    "df.column_z.mean()       # only calculate the mean\n",
    "df[\"column_z\"].mean()    # alternate method for calculating mean\n",
    "\n",
    "# count the number of occurrences of each value\n",
    "df.column_y.value_counts()   # most useful for categorical variables, \n",
    "# but can also be used with numeric variables\n",
    "\n",
    "#filter df by one column, and print out values of another column\n",
    "#when using numeric values, no quotations\n",
    "df[df.column_y == \"string_value\"].column_z\n",
    "df[df.column_y == 20 ].column_z    \n",
    " \n",
    "# display only the number of rows of the ‘df’ DataFrame\n",
    "df.shape[0]\n",
    "\n",
    "# display the 3 most frequent occurances of column in ‘df’\n",
    "df.column_y.value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Filtering and Sorting'''\n",
    "\n",
    "# boolean filtering: only show df with column_z < 20\n",
    "filter_bool = df.column_z < 20       # create a Series of booleans…\n",
    "df[filter_bool]                      # …and use that Series to filter rows\n",
    "df[filter_bool].describe()           # describes a data frame filtered by filter_bool\n",
    "df[df.column_z < 20]                 # or, combine into a single step\n",
    "df[df.column_z < 20].column_x        # select one column from the filtered results\n",
    "df[df[“column_z”] < 20].column_x     # alternate method \n",
    "df[df.column_z < 20].column_x.value_counts()   # value_counts of resulting Series, can also use .mean(), etc. instead of .value_counts()\n",
    "\n",
    "# boolean filtering with multiple conditions; indexes are in square brackets, conditions are in parens\n",
    "df[(df.column_z < 20) & (df.column_y=='string')]   # ampersand for AND condition \n",
    "df[(df.column_z < 20) | (df.column_z > 60)]        # pipe for OR condition\n",
    "\n",
    "# sorting\n",
    "df.column_z.order()                             # sort a column\n",
    "df.sort_values('column_z')                      # sort a DataFrame by a single column\n",
    "df.sort_values('column_z', ascending=False)     # use descending order instead\n",
    "\n",
    "# Sort dataframe by multiple columns\n",
    "df = df.sort(['col1','col2','col3'],ascending=[1,1,0])\n",
    "\n",
    "# can also filter ‘df’ using pandas.Series.isin \n",
    "df[df.column_x.isin([\"string_1\", \"string_2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Renaming,Adding and Removing Columns'''\n",
    "\n",
    "# rename one or more columns\n",
    "df.rename(columns={'original_column_1':'column_x', 'original_column_2':'column_y'}, \n",
    "          inplace=True) #saves changes \n",
    " \n",
    "# replace all column names (in place)\n",
    "new_cols = ['column_x', 'column_y', 'column_z']\n",
    "df.columns = new_cols\n",
    "\n",
    "# replace all column names when reading the file\n",
    "df = pd.read_csv('df.csv', header=0, names=new_cols)\n",
    "\n",
    "# add a new column as a function of existing columns\n",
    "df['new_column_1'] = df.column_x + df.column_y\n",
    "df['new_column_2'] = df.column_x * 1000   #can create new columns without for loops\n",
    "\n",
    "# removing columns\n",
    "df.drop('column_x', axis=1)   # axis=0 for rows, 1 for columns — does not drop in place\n",
    "df.drop(['column_x', 'column_y'], axis=1, inplace=True) # drop multiple columns\n",
    "\n",
    "# Lower-case all DataFrame column names\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Even more fancy DataFrame column re-naming\n",
    "# lower-case all DataFrame column names (for example)\n",
    "df.rename(columns=lambda x: x.split('.')[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Handling Missing Values'''\n",
    "\n",
    "# missing values are usually excluded by default\n",
    "df.column_x.value_counts()             # excludes missing values\n",
    "df.column_x.value_counts(dropna=False) # includes missing values\n",
    "\n",
    "# find missing values in a Series\n",
    "df.column_x.isnull()  # True if missing\n",
    "df.column_x.notnull() # True if not missing\n",
    "\n",
    "# use a boolean Series to filter DataFrame rows\n",
    "df[df.column_x.isnull()]  # only show rows where column_x is missing\n",
    "df[df.column_x.notnull()] # only show rows where column_x is not missing\n",
    "\n",
    "# understanding axes\n",
    "df.sum()       # sums “down” the 0 axis (rows)\n",
    "df.sum(axis=0) # equivalent (since axis=0 is the default)\n",
    "df.sum(axis=1) # sums “across” the 1 axis (columns)\n",
    "\n",
    "# adding booleans\n",
    "pd.Series([True, False, True])       # create a boolean Series\n",
    "pd.Series([True, False, True]).sum() # converts False to 0 and True to 1\n",
    "\n",
    "# find missing values in a DataFrame\n",
    "df.isnull()       # DataFrame of booleans\n",
    "df.isnull().sum() # count the missing values in each column\n",
    "\n",
    "# drop missing values\n",
    "df.dropna(inplace=True)             # drop a row if ANY values are missing, defaults to rows, but can be applied to columns with axis=1\n",
    "df.dropna(how='all', inplace=True)  # drop a row only if ALL values are missing\n",
    "\n",
    "# fill in missing values\n",
    "df.column_x.fillna(value='NA', inplace=True) \n",
    "# fill in missing values with ‘NA’\n",
    "# value does not have to equal a string — can be set as some calculated value like df.column_x.mode(), or just a number like 0\n",
    "\n",
    "# turn off the missing value filter\n",
    "df = pd.read_csv('df.csv', header=0, names=new_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split-Apply-Combine'''\n",
    "\n",
    "# for each value in column_x, calculate the mean column_y \n",
    "df.groupby('column_x').column_y.mean()\n",
    "\n",
    "# for each value in column_x, count the number of occurrences\n",
    "df.column_x.value_counts()\n",
    "\n",
    "# for each value in column_x, describe column_y\n",
    "df.groupby('column_x').column_y.describe()\n",
    "\n",
    "# similar, but outputs a DataFrame and can be customized\n",
    "df.groupby('column_x').column_y.agg(['count', 'mean', 'min', 'max'])\n",
    "df.groupby('column_x').column_y.agg(['count', 'mean', 'min', 'max']).sort_values('mean')\n",
    "\n",
    "# if you don’t specify a column to which the aggregation function should be applied, it will be applied to all numeric columns\n",
    "df.groupby('column_x').mean()\n",
    "df.groupby('column_x').describe()\n",
    "\n",
    "# can also groupby a list of columns, i.e., for each combination of column_x and column_y, calculate the mean column_z\n",
    "df.groupby([\"column_x\",\"column_y\"]).column_z.mean()\n",
    "\n",
    "#to take groupby results out of hierarchical index format (e.g., present as table), use .unstack() method\n",
    "df.groupby(\"column_x\").column_y.value_counts().unstack()\n",
    "\n",
    "#conversely, if you want to transform a table into a hierarchical index, use the .stack() method\n",
    "df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Selecting multiple columns and Filtering Rows'''\n",
    "\n",
    "# select multiple columns\n",
    "my_cols = ['column_x', 'column_y']  # create a list of column names…\n",
    "df[my_cols]                   # …and use that list to select columns\n",
    "df[['column_x', 'column_y']]  # or, combine into a single step — double brackets due to indexing a list.\n",
    "\n",
    "# use loc to select columns by name\n",
    "df.loc[:, 'column_x']                # colon means “all rows”, then select one column\n",
    "df.loc[:, ['column_x', 'column_y']]  # select two columns\n",
    "df.loc[:, 'column_x':'column_y']     # select a range of columns (i.e., selects all columns including first through last specified)\n",
    "\n",
    "# loc can also filter rows by “name” (the index)\n",
    "df.loc[0, :]       # row 0, all columns\n",
    "df.loc[0:2, :]     # rows 0/1/2, all columns\n",
    "df.loc[0:2, 'column_x':'column_y'] # rows 0/1/2, range of columns\n",
    "\n",
    "# use iloc to filter rows and select columns by integer position\n",
    "df.iloc[:, [0, 3]]     # all rows, columns in position 0/3\n",
    "df.iloc[:, 0:4]        # all rows, columns in position 0/1/2/3\n",
    "df.iloc[0:3, :]        # rows in position 0/1/2, all columns\n",
    "\n",
    "#filtering out and dropping rows based on condition (e.g., where column_x values are null)\n",
    "drop_rows = df[df[\"column_x\"].isnull()]\n",
    "new_df = df[~df.isin(drop_rows)].dropna(how='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
